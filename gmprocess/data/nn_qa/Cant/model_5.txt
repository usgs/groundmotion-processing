
##################################################
Model 5:
	Learning rate:	0.002
	Neuron in HL1:	20
	Neuron in HL2:	15
	Optimizer:	Nadam
	Dropout rate:	0.0
	Activation fx:	sigmoid
	Batch size:	16
	Learning rate decay:	0.0
	L1 regularizer:	0.0
	L2 regularizer:	1e-05
	Patience:	10
--------------------------------------------------
5-fold cross-validation result:	0.08623062310718237
##################################################

--------------------------------------------------
Validation on folder 1:
--------------------------------------------------
Epoch	Training loss	Validation loss
0	0.5501416869325196	0.3892972199689774
1	0.24656413543660624	0.1752247889062543
2	0.17189170229962147	0.14292015545446463
3	0.1469574654658646	0.13121331322664048
4	0.1367217556576458	0.12012605286306804
5	0.13189299911752497	0.12571830628238198
6	0.12659148885599486	0.11799517458151558
7	0.12074465118883265	0.11981165379119169
8	0.1198286739410916	0.11616643733502209
9	0.11295662825017537	0.1236808746078819
10	0.11975575868103147	0.11237214230307382
11	0.11093231005016695	0.14269692903118475
12	0.11229350823664434	0.10760086788265048
13	0.10597204143641925	0.10811741768636486
14	0.10878145244275964	0.3542506810422842
15	0.10924908433712359	0.11354601122895834
16	0.10677271535480412	0.1004982468857555
17	0.09792769016817635	0.09432606098563297
18	0.09959211517533051	0.16344456727150156
19	0.1004104150755242	0.09335438507941013
20	0.10222540516707047	0.09951466080580783
21	0.09760225099348706	0.09306159839544763
22	0.0968157402558869	0.15914814416413206
23	0.09981354005477058	0.08814234696570541
24	0.09445495481773607	0.10201241922750262
25	0.09707705435070073	0.09988943101840919
26	0.09215862539893929	0.09291046500020536
27	0.08982091860469413	0.08733957930982736
28	0.09589090687999717	0.09275596656448182
29	0.10050567161862595	0.09348801449599742
30	0.09177810066387293	0.08641400939716405
31	0.09429255346585483	0.14638515914324
32	0.08996682740536735	0.426316298610258
33	0.08738482265609875	0.09356625512521849
34	0.08456505834421388	0.10779449468731214
35	0.08866390404914672	0.08596961103409292
36	0.08887310935352111	1.0057880585706789
37	0.09937025239399745	0.10894505937501767
38	0.0847834415779261	0.08915126743735839
39	0.08797240886699567	0.10099058940436847
40	0.08398689165214163	0.12861903353015022
41	0.08686031152270025	0.10493810759107401
42	0.0889144865445095	0.1345825060411836
43	0.09115843745940981	0.08465023620644098
44	0.08897205117680894	0.08711800296907816
45	0.08347105330032048	0.3952941732658517
46	0.08889736478649024	0.10845363198364258
47	0.08287630544572396	0.08767350474614408
48	0.08202063572914836	0.08430219286028699
49	0.0825007030567282	0.08379598856603923
50	0.08201583877478529	0.08294141165371903
51	0.08320055604128052	0.08670909866834434
52	0.08427100615648758	0.08260420080432923
53	0.08115239833856878	0.08191791965497165
54	0.08239072789566723	0.081701653137666
55	0.08273909485846782	0.08496294066297834
56	0.08237095140014278	0.08100592067013636
57	0.08121679303641316	0.08464450699722054
58	0.08081344412429212	0.11367632090859922
59	0.07874187174599696	0.08295727759857714
60	0.0779911258511391	0.0806834086625263
61	0.08323417528046902	0.09116084550972356
62	0.07983388891360069	0.08169722994708847
63	0.07547914987857042	0.08292130789884822
64	0.07423770985895903	0.0863949424791463
65	0.07627657538090753	0.09591064074521544
66	0.07792731181754833	0.09506597739212956
67	0.08248778274479972	0.09844021396617396
68	0.07826394848505475	0.07829338133746347
69	0.07739732755801884	0.09471861511592526
70	0.07902836418479406	0.08482020528157865
71	0.07699942992312435	0.07269106915725924
72	0.07493635452414954	0.08143407150949815
73	0.07276602737020112	0.09091290303480423
74	0.07956265963301207	0.10557014313842268
75	0.07503530401823381	0.08231047045138448
76	0.07299033986156586	0.09228466120703095
77	0.07538434280537719	0.09448568461144351
78	0.07280492483179415	0.09171723598858925
79	0.07554074788448051	0.09777779960977975
80	0.07432257892780479	0.09964327910017293
81	0.07232627556129627	0.09144853486062644
--------------------------------------------------

--------------------------------------------------
Validation on folder 2:
--------------------------------------------------
Epoch	Training loss	Validation loss
0	0.483493936695022	0.30182129418849946
1	0.21034949871646616	0.21600058919191362
2	0.15327848209129585	0.1544736971159776
3	0.13539942149277573	0.21463557720184326
4	0.12821637458635338	0.12627595302462577
5	0.11872358693308009	0.1337551055153211
6	0.11188631940892328	0.13927078982194266
7	0.11335994603433015	0.13281256031741698
8	0.10697150069114926	0.11416968398789565
9	0.10611425033964954	0.12168916782488426
10	0.10147493786209232	0.11686532981693745
11	0.09828164301703483	0.14141263361275197
12	0.1002353032211681	0.1146232330451409
13	0.0956378692522263	0.10961985882868369
14	0.09734416602950394	0.1263642738809188
15	0.0911281979779266	0.12029670832678675
16	0.09344183882841697	0.1501992013603449
17	0.09128259032582625	0.12205623745918275
18	0.08883955890224093	0.11220400792236129
19	0.08613604432988516	0.10436733895043532
20	0.08800711369230634	0.11641797869155804
21	0.0863510784130175	0.10269623025755087
22	0.08489716675801155	0.09789658387005329
23	0.07873371624193348	0.12923937158783277
24	0.08328600469908434	0.1146396492322286
25	0.07935822449979328	0.11664904298633337
26	0.08195876806373997	0.12790360900511344
27	0.07715923459756942	0.11183054587741693
28	0.08162490903184964	0.10996381892760594
29	0.07693936610219133	0.1388206177279353
30	0.07697749162713687	0.12788968233019113
31	0.07546234416055592	0.1409324592774113
32	0.07982518537338455	0.11189962202558915
--------------------------------------------------

--------------------------------------------------
Validation on folder 3:
--------------------------------------------------
Epoch	Training loss	Validation loss
0	0.5207483424557199	0.3070653540747506
1	0.2218683874435562	0.1833768892288208
2	0.15583042751113288	0.18317213271345412
3	0.13336214861638254	0.1658408402119364
4	0.1290186241697922	0.13957707962819507
5	0.12229836905817333	0.1467612965830735
6	0.11814562339576885	0.13656176543661527
7	0.11316390994587819	0.13134271136351994
8	0.10750417252399509	0.13398826571447509
9	0.10909921197796897	0.13822360824261393
10	0.10284995566919553	0.14067972813333784
11	0.10259579546588787	0.15236622154712676
12	0.09813425640890495	0.13001319650028434
13	0.09805797908535535	0.14901286035776137
14	0.09653022031386872	0.13446319816367966
15	0.09659150645619245	0.12991704380937985
16	0.09757192376063024	0.12230937676770347
17	0.09102851073291125	0.1244481797516346
18	0.0911386970939825	0.12293489284813404
19	0.09008199226834791	0.1375229613589389
20	0.09378973369975742	0.13372815513185093
21	0.08689114085579519	0.11977992072701454
22	0.08769139617869108	0.14006548355732645
23	0.08600083834243764	0.1275570978916117
24	0.08903077850319284	0.12122180409197296
25	0.08555771469962682	0.12276350253926856
26	0.08865833112554584	0.12965601644345692
27	0.08995010411139015	0.13361825896160942
28	0.08964232459342737	0.11143231402550424
29	0.08452066986975695	0.1200744213696037
30	0.0856325950433346	0.11567201792129449
31	0.0833769186607582	0.11453216632562024
32	0.08308277446642626	0.10822463097316878
33	0.07820486215968354	0.11919826026473726
34	0.07865073757259537	0.11862155530069556
35	0.08068995530978382	0.12403285313929831
36	0.08174549192994189	0.12295673179839338
37	0.08016185505757872	0.12054802314511368
38	0.07623703466634528	0.12840120385800088
39	0.07667311416175082	0.11786363717700754
40	0.0786164689527677	0.11607217566775424
41	0.07673007128827221	0.11385837025940418
42	0.07618764364998118	0.10710513722683702
43	0.07469450388666538	0.1174152324455125
44	0.07257049510376058	0.10846101127564907
45	0.07161846465478056	0.12857794263533184
46	0.07285505948360446	0.12794999015118394
47	0.07503467404263482	0.1066161513168897
48	0.07344566364136103	0.11076029463005918
49	0.07471253249874647	0.13287796901272875
50	0.07262905843743532	0.11423022574079889
51	0.0678370127079191	0.10910202438810042
52	0.07360400540901603	0.10727307782641479
53	0.07018402318115072	0.10925757491162845
54	0.07060046978428852	0.11442393686622382
55	0.07339936371276276	0.10986334216381823
56	0.06961729906552987	0.10620923721896751
57	0.06808627009820595	0.10922327764332294
58	0.07558611715547472	0.13233292994754656
59	0.0709132511852135	0.10639672379408564
60	0.06833717994552722	0.1113460037112236
61	0.07081603621326976	0.11213901273906231
62	0.07093947832104114	0.10498663199799402
63	0.06642179427896258	0.12729941870485034
64	0.06915566131418986	0.11287824044270175
65	0.06970037075845029	0.12150972262557064
66	0.0680590365390233	0.10975530742002385
67	0.06895724442258155	0.10871710414333002
68	0.06877311873484215	0.1100470385061843
69	0.07023693778746419	0.10951529798763139
70	0.06450095545339712	0.1139362995326519
71	0.06420408085980218	0.11305029284209013
72	0.06489249681182903	0.12139721130686147
--------------------------------------------------

--------------------------------------------------
Validation on folder 4:
--------------------------------------------------
Epoch	Training loss	Validation loss
0	0.5100692742736116	0.28390536864244376
1	0.23767274476579967	0.14628374906229624
2	0.16572367530830082	0.12623372157760918
3	0.14265865944534115	0.10930476547181123
4	0.13050479298490683	0.09455063915849216
5	0.12446336350343547	0.08929448302177112
6	0.11961672184621272	0.08341077359082295
7	0.1167078222994866	0.10437683692893295
8	0.1108093051447387	0.07713850380209798
9	0.10471599443789299	0.0891143340146474
10	0.10628963965197835	0.07623331608308095
11	0.1054532353499845	0.07697718617969722
12	0.10183921386138088	0.0828657933507821
13	0.10129328703665876	0.09585285660730769
14	0.09826801547021392	0.08053581639852622
15	0.09543446723373045	0.07839237526889341
16	0.0966740675606263	0.09124768701664246
17	0.0914826065216017	0.07640235253264056
18	0.09516180308885062	0.07023572981375688
19	0.08635107352692079	0.06874498623880637
20	0.08587812633623496	0.07131755515114922
21	0.09274392687968346	0.10153955932120932
22	0.08408265992988667	0.06892095495247837
23	0.08115258100896376	0.07237373716446965
24	0.08814663483969115	0.08841668643099611
25	0.08540727061499594	0.07393771297686297
26	0.08308755250311307	0.06907689440210547
27	0.08213199376851747	0.07619833318000385
28	0.08527373624272667	0.07328216224528451
29	0.08108486084854982	0.07149373910826068
--------------------------------------------------

--------------------------------------------------
Validation on folder 5:
--------------------------------------------------
Epoch	Training loss	Validation loss
0	0.46948799827824467	0.2945197277598911
1	0.2252133309841156	0.1839359935786989
2	0.16303108025720153	0.16416130993101333
3	0.13900801210083824	0.13502443209290504
4	0.13083821841772053	0.137220662418339
5	0.12215528158821921	0.12961850418812698
6	0.12260934963714386	0.13642890157385004
7	0.11788963693855466	0.12546857450571325
8	0.1149059581718799	0.12093485212988324
9	0.11356853633255198	0.12454799272947842
10	0.11245104578202185	0.11282749118076431
11	0.10521250314794589	0.11186113440328174
12	0.10673439113180275	0.10955100998075472
13	0.10479071474215691	0.11161431243850126
14	0.10310172449419464	0.10694468453940419
15	0.10103721947179756	0.19111190827356445
16	0.10340922768565192	0.11059277771661678
17	0.09948575394093126	0.11676162346783611
18	0.09696255491479583	0.1380909358461698
19	0.09553164354107087	0.09951488643677699
20	0.09331982759083958	0.10558523142503368
21	0.09085902236402035	0.13795550405565235
22	0.09152368138665738	0.10672459593042731
23	0.0910779675360823	0.10001598830438323
24	0.08942688893580782	0.11380428734959827
25	0.09131441736944776	0.09695350606408384
26	0.09324748058789882	0.11402421223206652
27	0.08632669030297277	0.09967062678188085
28	0.09248505701459404	0.11468979877730211
29	0.08667607902400735	0.09355362525416745
30	0.08478146091616456	0.1207963414904144
31	0.0832765571800047	0.12643904601120287
32	0.0821431977485401	0.09984282961943083
33	0.08710163103659516	0.10026209986665183
34	0.08091534889586594	0.09009702350530359
35	0.08341767217801965	0.09195668501779437
36	0.08493379375802866	0.12087837662547826
37	0.07998811192810536	0.09847124885353777
38	0.0780230619188776	0.12366131987008784
39	0.08136945125930335	0.10428059974478351
40	0.07831140585189712	0.08866132511239913
41	0.07692536608842404	0.08683384427179892
42	0.07726064928253924	0.10276539494386977
43	0.07806574913362661	0.0907428352886604
44	0.07741956264050542	0.08691479764464828
45	0.07507700531109088	0.14561283407318923
46	0.07397884239537128	0.09642925810896688
47	0.07519231442686009	0.10981431417167187
48	0.07916584362316391	0.1268437587759561
49	0.07415927444193242	0.10243154546866814
50	0.0802381887384083	0.09813078956471549
51	0.06983711733010368	0.12359007976742255
--------------------------------------------------


